---
title: "Proj1_kl2739"
author: Ka Heng (Helen) Lo
runtime: shiny
output: html_notebook
---
#Intro:  
This is a partly interactive R Markdown Notebook. The first part involves broad and close analyses of presidential inauguration speeches, while the second (interactive) part expands on ideas in the first part to allow for a more general application of close analysis ideas on user-selected subsets of the data on inaugural speeches. 
  
#Set-Up: Install & Load Libraries; Set Preliminary Knitr Setting Options  
```{r "setup", include=FALSE}
require("knitr")
opts_knit$set(root.dir = "~/Desktop/Applied Data Science/Proj1")

used <- c("tm", "SnowballC", "RColorBrewer", "ggplot2", "wordcloud", "biclust",
          "cluster", "igraph", "fpc", "dplyr", "plyr", "tidytext", "stringr", 
          "rvest", "tibble", "qdap", "sentimentr", "gplots",
                 "syuzhet", "factoextra", 
                "beeswarm", "scales",
                "RANN", "topicmodels", "rsconnect" , "xlsx")

# check packages that need to be installed.
needed=setdiff(used, intersect(installed.packages()[,1], used))

# install additional packages
if(length(needed)>0){
  install.packages(needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}

library(tm)
library(tidytext)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(plyr)
library(stringr)
library(rvest)
library(tibble)
library(qdap)
library(sentimentr)
library(gplots)
library(syuzhet)
library(factoextra)
library(beeswarm)
library(scales)
library(RANN)
library(topicmodels)
library(rsconnect)
library(xlsx)

#Get info from the R script that contains functions called in this html notebook
source("../lib/Functions.R")
```

*Note*: This notebook was prepared with the following environmental settings.  
```{r}
print(R.version)
```
  
#More Set-Up: Read in the Speeches & the 'InaugurationDates.txt' File  
```{r} 
##Create global variables: 
#Read in the speeches
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)

ff.all<-Corpus(DirSource(folder.path))

#Reading in InaugurationDates.txt; global variable for dates data
dates <- read.delim("../data/InaugurationDates.txt") ; #dates
```

#Pre-Processing Text:  (Guided by in-class Tutorial)
For the speeches, we remove extra white space, convert all letters to the lower case, remove [stop words](https://github.com/arc12/Text-Mining-Weak-Signals/wiki/Standard-set-of-english-stopwords), removed empty words due to formatting errors, and remove punctuation. Essentially, we have only the *significant* words of each speech left to work with. Then we compute the Document-Term Matrix (DTM) and its transpose, the Term-Document Matrix (TDM).  
```{r}
#preprocessing data
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)

#stage the data; create a document term matrix (what we will use from this point on)
#Term-Document Matrix is transpose of Document-Term Matrix
tdm.all<-TermDocumentMatrix(ff.all)
tdm.tidy=tidy(tdm.all)

#Apply/Split/Combine Method to aggregate sums 
tdm.overall=ddply(tdm.tidy,.(term),summarise,total_count=sum(count))
```

#Inspect an Overall Wordcloud:  
Now that we've essentially cleaned our data, we can work with it. The easiest way to visualize our data is to create a wordcloud (following the tutorial from class). Since we're just starting our exploration of our data, let's just look at a wordcloud for all the significant words in all the presidential inaugural speeches. 
```{r, fig.height=6, fig.width=6}
wordcloud(tdm.overall$term, tdm.overall$total_count,
          scale=c(5,0.5),
          max.words=100,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          use.r.layout=T,
          random.color=FALSE,
          colors=brewer.pal(9,"Blues"))
```
  
Notice that the words that pop out the most are very commonly associated with hope, strength, and status: "will", "people", "can", "states", "great", "nation", "world", "may", "freedom", etc. It is not very surprising that these are the words that appear most frequently across all the US presidential inauguration speeches. While this is not new information, we get minor relief that our preliminary assumptions are confirmed.  

#Compute TF-IDF Weighted Document-Term Matrices for Individual Speeches: (from class)  
As we would like to identify interesting words for each inaugural speech, we use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to weigh each term within each speech. It highlights terms that are more specific for a particular speech. Additionally, we use the function *tidy()* from the *tidytext* package to shape our dataset into the most useable format.  

```{r}
dtm <- DocumentTermMatrix(ff.all,
                          control = list(weighting = function(x)
                                             weightTfIdf(x, 
                                                         normalize =FALSE),
                                         stopwords = TRUE))
ff.dtm=tidy(dtm)
```

#Interactive:  Visualize Important Words in Individual Speeches  
We envoke the *shiny* library in *R* to give us an interactive experience when visualizing significant words from individual speeches. Essentially, we using the *shinyApp()* function we can allow users to choose two speeches whose wordcloud they want to compare side by side. In a new interactive window, we can choose two speeches - one from each drop-down menu - and the two respective wordclouds appear side-by-side for easy visual comparison.  
```{r, warning=FALSE}
library(shiny)
library(rsconnect)

shinyApp(
    ui = fluidPage(
      fluidRow(style = "padding-bottom: 20px;",
        column(4, selectInput('speech1', 'Speech 1',
                              speeches,
                              selected=speeches[5])),
        column(4, selectInput('speech2', 'Speech 2', speeches,
                              selected=speeches[9])),
        column(4, sliderInput('nwords', 'Number of words', 3,
                               min = 20, max = 200, value=100, step = 20))
      ),
      fluidRow(
        plotOutput('wordclouds', height = "400px")
      )
    ),

    server = function(input, output, session) {

      # Combine the selected variables into a new data frame
      selectedData <- reactive({
        list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
             dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
             dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
             dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
      })

      output$wordclouds <- renderPlot(height = 400, {
        par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
        wordcloud(selectedData()$dtm.term1, 
                  selectedData()$dtm.count1,
              scale=c(4,0.5),
              max.words=input$nwords,
              min.freq=1,
              random.order=FALSE,
              rot.per=0,
              use.r.layout=FALSE,
              random.color=FALSE,
              colors=brewer.pal(10,"Blues"), 
            main=input$speech1)
        wordcloud(selectedData()$dtm.term2, 
                  selectedData()$dtm.count2,
              scale=c(4,0.5),
              max.words=input$nwords,
              min.freq=1,
              random.order=FALSE,
              rot.per=0,
              use.r.layout=FALSE,
              random.color=FALSE,
              colors=brewer.pal(10,"Blues"), 
            main=input$speech2)
      })
    },

    options = list(height = 600)
)
```

#Quantifying Frequencies of Words:  
Of course it is great to be able to visualize the significant words, but we may also want to quantify the frequencies of significant words. Let's look at the breakdown of frequencies of the 20 most frequently used words across all the inauguration speeches. Here, they are sorted in descending order. So, while the wordclouds gives us a visual in terms of darkness of color and size of the word, we can also consider the numerical difference.   
```{r}
freq<-rowSums(as.matrix(tdm.all))
head(sort(freq,decreasing=T),20)
```
  
Notice that "will" has a frequency of 912, which is significantly greater than the second most frequently-used word, "people", which only comes to a total of 567 appearances. We get a slightly different understanding of the differing frequncies between the uppermost percentile of frequently-used words in inauguration speeches. This is a more tangible representation.  
  
Additionally, we can look at all the terms that have a frequency greater than 125 across all the US presidential inauguration speeches.  
```{r}
findFreqTerms(tdm.all,lowfreq = 125)
```
  
There are 48 words with a frequency of 125 or higher across all the inauguration speeches. It doesn't appear that any of the words are unusual, in the sense that it's surprising the word would be in an inauguration speech. Though, I do notice that "men" appears in this list of frequently used words, while "women" does not.  
  
#Plot Word Frequencies:    
```{r}
#plot word frequencies
library(ggplot2)
wf <- data.frame(word=names(freq),freq=freq)
p <- ggplot(subset(wf,freq>125), aes(word,freq))
p <- p+ geom_bar(stat="identity")
p <- p+ theme(axis.text.x=element_text(angle=45,hjust=1))
p <- p+ ggtitle("Plot of Word Frequencies, for f>125")
p
```


#Subsetting the Data: Look at Speechs Containing Keywords  
Since I noticed that "men" appears more that 125 times while "women" does not, I decided to find out how many times "women", and what I call its equivalents, "woman", "girls","girl", appear. Additionally, I was curious as to which particular speeches mentioned women. So in subsetting the data, we can get a closer look at the specific speeches that mention women and even the specific sentences in those speeches that explicitly use the word "women" or its equivalents.   
```{r}
#Select a class of equivalent terms; in this case, we look at "women"
term.vector <- c("women", "woman", "girls", "girl")

#Subset our dataset to include only speeches in which any of the words in term.vector appear
tdm.tidy.women <- get.tdm.tidy.term(tdm.tidy,term.vector)

#Since each word in term.vector is considered equivalent, we use split/apply/combine method to summarize the number of times "women" and its equivalents are mentioned in each speech
(instances.women <- get.instances(tdm.tidy.women))

```

```{r}

#Use get.speeches(tdm.tidy.term) to get only the filenames of the speeches that mention "women" and its equivalents
speeches.women <- get.speeches(tdm.tidy.women)

#Use get.ff.term(folder.path,speeches.term) to get a corpus object of only those relevant speeches
ff.women <- get.ff.term(folder.path,speeches.women)

#Use assoc.words(folder.path,speeches.term,x), which calls on association(my.corpus,term.vector,x) to get a list of vectors of words associated with each incidence of "women" and its equivalents
    #associated words are 'significant' words (e.g., not stopwords) that are some x     valued in front or behind an incidence of "women" and its equivalents
(assoc.women <- assoc.words(folder.path,speeches.women,x=10))

#should be 16 speeches in the new corpus 
```

```{r}
#Use get.speech.date(speeches.term) to get a dataframe with two columns: (1) Speech (file name) and (2) Date
    #each row is an incidence of an inaugural speech that mentions at least one word       in term.vector at least once 
    #specifically, we get a dataframe of the filename of each speech that mentions       "women" and the date of address, ordered by year in ascending order from top to      bottom
(dated.speeches.women <- get.speech.date(speeches.women))
```
  
```{r}
#Use full.text(ff.term, dated.speeches.term) to get a dataframe with 3 columns: Speech, Date, Full Speech Text
  #each row in the dataframe corresponds to one of the inaugural speeches that        contain "women" or its equivalents, in term.vector
dated.speeches.women.f <- full.text(ff.women,dated.speeches.women)

#Export the dataframe to an excel file in the Output folder
file.name <- "../output/dated.speeches.women.xlsx"
write.xlsx(dated.speeches.women.f,file.name,row.names=F)

```
  
#Data Processing: Generate a List of Sentences (from class)  
We want to use sentences as units of analysis for this project, as sentences are natural languge units for organizing thoughts and ideas. For each extracted sentence, we apply sentiment analysis using [NRC sentiment lexion](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm). "The NRC Emotion Lexicon is a list of English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive)." We also assign an sequential id to each sentence in a speech (`sent.id`) and also calculated the number of words in each sentence as *sentence length* (`word.count`).  
```{r}
#Use get.sentences(dated.speeches.term.f) to get sentence.list 
sentence.list <- get.sentences(dated.speeches.women.f)
#head(sentence.list,5)

#sentence.list is a list of dfs, each element of list corresponds to an inauguration speech that mentions "women" (and the like)
#each df in the list has 13 columns : sentences, word.count, anger, anticipation, disgust, fear, joy, sadness, surprise, trust, negative, positive, sent.id
#each row in each df corresponds to a sentence in the speech

#Export our file into an Excel Workbook in the output folder
#each sheet in the workbook corresponds to a specific speech
file.name = "../output/sentence.list.xlsx"
write.xlsx(sentence.list[[1]],file.name,
           sheetName = names(sentence.list)[1],row.names = F)
for (i in 2:length(sentence.list)){
  write.xlsx(sentence.list[[i]], file.name,
             sheetName = names(sentence.list)[i],append=T,row.names=F)
}
```
  
#More Subsetting: Finding Sentences that Contain the Keywords  
For each of the 16 speeches that mention women, we want to focus on the actual sentences that contain the word "women", "woman", "girls", or "girl". So, we can subset the data from our sentiment analysis on each extracted sentence (stored in *sentence.list*, which is a list of dataframes with each element corresponding to a specific speech) to get sentiment analysis data on each sentence that contains the word "women", "woman", "girls", or "girl".  Call our new list object *sentence.list.women*. Then, *sentence.list.women* contains subsetted data from *sentence.list* that pertains only to the sentences that mention women.   
```{r}
#Use get.sentences.term(sentence.list) to subset sentence.list, extracting only the   sentences that explicitely mention "women"
sentence.list.women <- get.sentences.term(sentence.list,term.vector)
```
  
Let's check that our new list, *sentence.list.women*, is what we want. The length of our new list should be 16, and each element (dataframe) of our new list should have 13 columns.  
```{r}
#create empty vector for number of columns in each dataframe in sentence.list.women
num.cols <- NULL 
#iterate over each dataframe in list
for (i in 1:16){
  #append the value of ncol(df) to the vector num.cols
  num.cols <- c(num.cols,ncol(sentence.list.women[[i]]))
}

check.1 <- cbind(length(sentence.list.women))
colnames(check.1) <- "Length"
check.2 <- cbind(as.character(length(unique(num.cols))==1))
colnames(check.2) <- "(T/F) Each df has same number of columns?"
check.3 <- cbind(num.cols[1])
colnames(check.3) <- "How many columns?"

check.1 ; check.2 ; check.3
```
  
We can preview our new list:  
```{r}
head(sentence.list.women)
```
  
Now, let's export the data from our new list into an Excel workbook in our project's *output* folder. We may put each dataframe in the list, *sentence.list.women*, in it's own sheet of the workbook, and we name the sheet by the file name of the corresponding speech. Call it *sentence.list.women.xlsx*.  
```{r}
#library(xlsx)
file.name <- "../output/sentence.list.women.xlsx"
write.xlsx(sentence.list.women[[1]],file.name,
           sheetName = names(sentence.list.women)[1],row.names=F)
for (i in 2:16){
  write.xlsx(sentence.list.women[[i]], file.name,
             sheetName = names(sentence.list.women)[i],append=T,row.names=F)
}
```
  
Now we find the aggregate average of each quantitative variable from the *sentence.list.women* data frame. In other words, for each of the 16 speeches that mention "women", "woman", "girls", or "girl", we take each sentence in the speech that actually contains "women", "woman", "girls", or "girl" and find the mean over the total number of those sentences of each of our 12 quantitative variables: *word.count*, *anger*, *anticipation*, *disgust*, *fear*, *joy*, *sadness*, *surprise*, *trust*, *negative*, *positive*, *sent.id*.  
```{r}
my.function <- function(df){
  if (nrow(df) == 1) {
    return(df[,2:13])
  }
  else {
  num.df <- apply(df[,2:13],2,as.numeric)
  return(colMeans(num.df))
  }
}
sent.data.women <- sapply(sentence.list.women,my.function)
sent.data.women <- apply(sent.data.women,c(1,2),as.numeric)
rownames(sent.data.women) <- paste("Avg",rownames(sent.data.women),"/Sent")
(sent.data.women <- t(sent.data.women))


file.name <- "../output/sent.data.women.xlsx"
write.xlsx(sent.data.women,file.name,row.names=T)
```

We can find the maximum average sentiment value per sentence among all 16 speeches that mention women.  
```{r}
max.value <- apply(sent.data.women,2,max)
max.source <-rownames(sent.data.women)[as.vector(apply(sent.data.women,2,which.max))]
cbind(max.value,max.source)
```
  
Note that Herbert Hoover's first-term inauguration speech has the most association with anger and disgust when mentioning women. He delivered his adress on `r df.speeches.women[max.source[2],2]`. The sentences in his speech that actually mention women are  
>`r sentence.list.women[[max.source[2]]][,1]`  
  
Now compare those sentences to those in Barack Obama's first-term inauguration speech, which was delivered on `r df.speeches.women[max.source[6],2]`  
>`r sentence.list.women[[max.source[6]]][,1]`  
  
As a quick note, in both speechs, women are only mentioned as part of a grouping with men (and children) - "men and women (and children)" or "boy and girl". This is not surprising, as such is the common rhetoric when referencing a population of people. We expect that women are grouped together with men in all the other inauguration speeches that mention women as well.  
  
Now specifically, it is clear that Hoover's time as president was during the Prohibition, as he calls on responsible men and women to do the greatest national service of following Prohibition laws and denouncing any outlaws. We can understand why Hoover's speech ranked the most angry and the most disgusted when directly referencing women in context. He makes a clear distinction between "honest" and dishonest men and women, with the former being those who do their "duty" and obey the law. This focus on the civic duty of men and women is attributed to WWI and the rise of nationalism. Wartime strife required both men and women to step into new roles, such that this early mention of women in a presidential inauguration speech is very fitting. Additionally, in the context of post-war relief, Hoover mentions girls as a part of the solution to rebuilding a better America. Again, the sentiment of Hoover's address to women is the same - troubled times give rise to new opportunities for men *and women*, for boys *and girls*. Find out more about: [Herbert Hoover's Presidency](https://en.wikipedia.org/wiki/Herbert_Hoover).  
  
In contrast, [Obama's presidency](https://en.wikipedia.org/wiki/Presidency_of_Barack_Obama) was not during wartime, and, expectedly so, his references to women echo joy and hope more clearly that Hoover's. Obama praises the men and women who have worked hard for a better life and shows gratitude to them for paving the way for his inauguration. He speaks of men, women, and children as coming from "every race and every faith" and declares his hope for peace in the future. Obama's speech is saturated with words that elicit joy and warmth, which appropriately reflects the great milestone in US history of electing the first multiracial president. Often race and gender are lumped together in dialogue, and so it is apt that Obama's speech explicitly mentions women 5 separate times (the most of all other inauguration speeches). 

Similarly, we can find the minimum average sentiment value per sentence among all 16 speeches that mention women.  
```{r}
min.value <- apply(sent.data.women,2,min)
min.source <-rownames(sent.data.women)[as.vector(apply(sent.data.women,2,which.min))]
cbind(min.value,min.source)
```
  
Notice that William J Clinton's first-term inauguration speech is the least positive when mentioning women, which is consistent with our previous findings that his speech is the most negative when mentioning women. Let's see the sentence(s) in which women are explicitely mentioned in Clinton's speech:  
>`r sentence.list.women[[min.source[11]]][,1]`  
  
It appears women are mentioned only once in Clinton's entire speech. In the context of [Clinton's presidency](https://en.wikipedia.org/wiki/Bill_Clinton), this singular mention may or may not be significant. As far as the lack of positivity in this sentence, we can probably attribute that to the choice of strong negative words like  "sacrifice", "depression", "fascism", and "communism", which take away from the few postive ones like "thank", "steadfastness", and "triumphed".  

#Interactive: Exploratory Analysis of Keywords in Inauguration Speeches  
```{r}
library(shiny)
folder.path="../data/InauguralSpeeches/"

ui <- navbarPage("Applied Data Science: Project 1",
             titlePanel("US Presidential Inauguration Speeches:"), 
             h2("Exploratory Analysis of Keywords in Presidential
                Inauguration Speeches"),
             hr(),
             p("Let's explore the diction of inauguration speeches: 
               What words are popularly chosen? What words are a bit contended? 
               Can we learn anything about a specific inauguration speech and more
               generally a specific president's term by doing a close analysis of
               the sentences in which certain keywords are explicitely used? In what
               context are certain keywords used? And how does the sentiment or
               emotion behind the sentence that contains a keyword change as the
               context changes? Can we make any generalizations about word choice
               in presidential inauguration speeches?"),
             p("Below, enter four keywords you may (or may not) expect to find in 
               a presidential inauguration speech: "), 
            fluidRow(
              column(3, textInput("term1", label = "Keyword 1", value="women")),
              column(3, textInput("term2", label = "Keyword 2", value="woman")),
              column(3, textInput("term3", label = "Keyword 3", value="girls")),
              column(3, textInput("term4", label = "Keyword 4", value="girl")),
              br(),hr()),
            fixedRow(
              column(12,align="center",actionButton("continue",label="Continue")),
              tags$style(type='text/css', "#continue { vertical-align: middle; height: 50px; width: 100%; font-size: 30px;}")
              ),
          
       tabsetPanel(position="below",      
        tabPanel("Data 1",
           h3("Incidences of Keywords in US Presidential Inauguration Speeches"),
           dataTableOutput("instances.input")),
        tabPanel("Data 2",
                 h3("Words Associated with Keywords in US Presidential Inauguration
                    Speeches"),
                 verbatimTextOutput("assoc.input")),
        tabPanel("Data 3",
                 h3("Table of Speeches that Contain the Keywords, Including Full
                    Text"),
                 tableOutput("dated.speeches.input.f")),
        tabPanel("Data 4",
                 h3("Data from Sentiment Analysis on Sentences Containing
                    Keywords"),
                 verbatimTextOutput("sentence.list.input"))))
             

server <- function(input,output,session){
  term.vector <- reactive({c(as.character(input$term1),
                             as.character(input$term2),
                             as.character(input$term3),
                             as.character(input$term4))})
 
  tdm.tidy.input <- reactive({get.tdm.tidy.term(tdm.tidy,term.vector())})
  output$instances.input <- 
    renderDataTable({get.instances(tdm.tidy.input())})
  
  speeches.input <- reactive({get.instances(tdm.tidy.input())[,1]})
  ff.input <- reactive({get.ff.term(folder.path,speeches.input())})
  output$assoc.input <- renderPrint({
    speeches <- speeches.input() 
    assoc.words(folder.path, speeches,x=10)
    })

  
  dated.speeches.input <- reactive({get.speech.date(speeches.input())})
  
  output$dated.speeches.input.f <- renderTable({
    ff. <- ff.input()
    dated.speeches. <- dated.speeches.input()
    full.text(ff.,dated.speeches.)
    })

  dated.speeches.input.f <- reactive({
    ff. <- ff.input()
    dated.speeches. <- dated.speeches.input()
    full.text(ff.,dated.speeches.)
    })
  sentence.list.f <- reactive({
    d.s.input.f <- dated.speeches.input.f()
    get.sentences(d.s.input.f)
    })

  output$sentence.list.input <- renderPrint({
    sent.l.f <- sentence.list.f()
    term.v <- term.vector()
    get.sentences.term(sent.l.f,term.v)
    })
}

shinyApp(ui=ui,server=server)
```

